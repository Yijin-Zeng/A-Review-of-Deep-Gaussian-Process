# A Review of Deep Gaussian Process: Learn Meaningful  Embedding with Extreme Small Dataset

A report for CDT deep learning course (2021). In this report, we review deep Gaussian processes [1] for learning meaningful embedding with extreme small dataset. We begin by revisiting Gaussian process models and single-layer Gaussian process latent variable models. Then, we focus on the deep Gaussian processes architecture, and its kernel design. The performance of deep Gaussian process models are evaluated on the MNIST dataset for figures generating.

We analyze the effects of sample size and model depth on the model performances. We find out that even for extreme small sample size, e.g. 10 instances, the model learns meaningful latent representation.

## References

[1] Damianou A, Lawrence ND. Deep gaussian processes. InArtificial intelligence and statistics 2013 Apr 29 (pp. 207-215). PMLR.
